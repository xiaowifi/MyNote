## 资料
* [google Android media 官网](https://developer.android.com/reference/android/media/package-summary)
* [google MediaExtractor官网](https://developer.android.com/reference/android/media/MediaExtractor)
* [google MediaCodec ](https://developer.android.com/reference/android/media/MediaCodec)
* [google MediaProjectionManager 屏幕录制](https://developer.android.com/reference/android/media/projection/MediaProjectionManager)

# 正文 
在Android 系统中，屏幕录制需要调用系统服务。而这个服务就是MediaProjectionManager，我们需要向系统发送屏幕录制的申请。
然后设置编码器，通过对于MediaProjectionManager提供的对象提供输出到数据，编码后，通过IO流 存储到文件中。
## MediaProjectionManager的使用
### 权限申请
````aidl
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/>
    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
    <uses-permission android:name="android.permission.CAMERA"/>
````
### 生成intent对象
````java
  mediaProjectionManager = (MediaProjectionManager)getActivity().getSystemService(Context.MEDIA_PROJECTION_SERVICE);
        // 发起请求录屏的意图
        Intent captureIntent = mediaProjectionManager.createScreenCaptureIntent();
        getActivity().startActivityForResult(captureIntent,1);
````
### 权限申请监听
```java
 @Override
    public void onActivityResult(int requestCode, int resultCode, @Nullable Intent data) {
        super.onActivityResult(requestCode, resultCode, data);
        if (resultCode!=RESULT_OK||requestCode!=1) {
            return;
        }
        // 我们就获取到 MediaProjection 进行录屏操作。
        MediaProjection mediaProjection = mediaProjectionManager.getMediaProjection(resultCode, data);
        //
        try {
            H264Encoder encoder=new H264Encoder(mediaProjection);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
```
### 为MediaProjection提供输出
在Android系统中，视频播放需要使用一个Surface，而输出也可以需要一个Surface。
## H264编码
我们需要通过MediaProjection 提供的数据源去编码。但是有一些内容需要注意。在解码的时候，因为我们数据中存在SPS和PPS,所以，我们只需要明确
解码器的mini，然后宽高都可以乱写。但是在编码过程的时候，宽高、帧、等信息就需要提供，这个会影响到编码后的数据，同时生成的SPS和PPS也是基于我们编码的时候
提供的MediaFormat。
### 编码器准备 
因为SPS和PPS是基于我们MediaFormat的，所以有一些数据是必须要提供的。
````java
    public H264Encoder(MediaProjection mediaProjection) throws IOException {
        this.mediaProjection = mediaProjection;
        mediaCodec = MediaCodec.createEncoderByType(MediaFormat.MIMETYPE_VIDEO_AVC);
        int width=720;
        int height=1280;
        // 获取 mediaFormat ，在解码的时候可以乱传，但是在编码的时候，就不能乱传。
        MediaFormat format = MediaFormat.createVideoFormat(MediaFormat.MIMETYPE_VIDEO_AVC, width, height);
        // 帧率 1秒20帧
        format.setInteger(MediaFormat.KEY_FRAME_RATE,20);
        // i帧间隔。30帧后一个I帧，我们知道I帧数据可以不依赖于其他帧完整的解析出来。所以一个视频中I帧越多，文件大小越大。
        // 通常直播的时候帧率低，但是I帧的间隔小，但是在短视频等固定场景中，帧率会提高，I帧间隔会加大
        format.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL,30);
        // 码率，码率越高代表质量越清晰，可以理解为压缩等级，越小压缩比例越高。因为H264编码是有损压缩。所以越大还原度越高
        format.setInteger(MediaFormat.KEY_BIT_RATE,width*height);
        // 这个值必须传递。这个是编码器的数据来源。我们屏幕录制，mediaProjection提供的数据的来源是Surface
        format.setInteger(MediaFormat.KEY_COLOR_FORMAT, MediaCodecInfo.CodecCapabilities.COLOR_FormatSurface);
        //Surface是输出对象。  flags 为编码的标志，默认是解码。
        // 因为我们是编码，所以不需要提供一个Surface用于输出，所以Surface不需要设置。MediaCodec.CONFIGURE_FLAG_ENCODE 作为编码标志位，表示我们这个是编码器。
        mediaCodec.configure(format,null,null,MediaCodec.CONFIGURE_FLAG_ENCODE);
        // Surface 将mediaProjection绑定。
        Surface inputSurface = mediaCodec.createInputSurface();
        //将 Surface和mediaProjection绑定，这样，录屏生成的数据就会存放到Surface里面。  dpi 用于表示1dpi输出几像素,flags 表示关系。
        mediaProjection.createVirtualDisplay("唯一的名称",width,height,2, DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC,inputSurface,this,null);
        // 开启编码器 
        mediaCodec.start();
}
````
### 编码
因为上面我们通过mediaProjection.createVirtualDisplay将mediaCodec 和mediaProjection进行了关联，所以我们不需要和播放的
的时候那样手动去输入数据。他会帮我们把输入过程省略。所以我需要做的就是拿到数据输出数据，然后进行处理。
````java
 @Override
    public void run() {
        // 因为我们不需要理会输入，那么只有输出过程了。
        MediaCodec.BufferInfo info=new MediaCodec.BufferInfo();
        FileUtils utils=new FileUtils("_H264Encoder_");
        while (true){
            int outIndex = mediaCodec.dequeueOutputBuffer(info, 10000);
            if (outIndex>=0){
                // 这个是数据容器。所以不能直接操作他。
                ByteBuffer byteBuffer = mediaCodec.getOutputBuffer(outIndex);
                byte [] ba=new byte[info.size];
                // 将容器中数据转移到我们自定义的数组中。
                byteBuffer.get(ba);
                // 将数据存储到某个地方。
                utils.appendH264(ba);
                // 释放,因为没有Surface 需要渲染，就传递false,true 是帮忙渲染到屏幕上。
                mediaCodec.releaseOutputBuffer(outIndex,false);
            }
        }
    }
````
## 结束录制
我在尝试将mediaCodec 暂停或者重置之后， mediaCodec.dequeueOutputBuffer都会报错。
我们停止屏幕录制的流程大概是，停止输入，停止输出，停止编码器，停止循环。
因为我们获取输出数据的时候允许了10000的延时，所以这个停止编码器会报错。

# 总结 
通过这个流程，如果将输出到H264 文件转成16进制进行解析的话。就可以知道：
* 000001是帧分隔符。
* 65是1帧开始
* pps 开始是68
* sps 开始是67 
* 先输出的是sps和pps
* sps 存储了我们之前mediaFormat 中数组的参数。
这些都个之前文档相对应。其实sps和pps在开发过程中会存在多个，但是mediaCodec 中只会帮忙生成一个。
